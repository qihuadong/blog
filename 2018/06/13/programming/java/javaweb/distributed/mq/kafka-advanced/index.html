<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/blog/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/blog/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/blog/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/blog/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="java,分布式,javaweb,mq,">





  <link rel="alternate" href="/blog/atom.xml" title="张鹏的博客" type="application/atom+xml">






<meta name="description" content="Kafka Kafka 是一个分布式的、可水平扩展的、基于发布/订阅模式的、支持容错的消息系统。    1. 概述 1.1. 分布式 1.2. 容错 1.3. 提交日志 1.4. 消息队列 1.5. 为什么要使用消息系统 1.6. Kafka 的关键功能 1.7. Kafka 基本概念 1.8. Kafka 核心 API 1.9. Topic 和日志   2. Kafka 工作原理 3. 持久化">
<meta name="keywords" content="java,分布式,javaweb,mq">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka">
<meta property="og:url" content="http://yoursite.com/2018/06/13/programming/java/javaweb/distributed/mq/kafka-advanced/index.html">
<meta property="og:site_name" content="张鹏的博客">
<meta property="og:description" content="Kafka Kafka 是一个分布式的、可水平扩展的、基于发布/订阅模式的、支持容错的消息系统。    1. 概述 1.1. 分布式 1.2. 容错 1.3. 提交日志 1.4. 消息队列 1.5. 为什么要使用消息系统 1.6. Kafka 的关键功能 1.7. Kafka 基本概念 1.8. Kafka 核心 API 1.9. Topic 和日志   2. Kafka 工作原理 3. 持久化">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-core-api.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-log-anatomy.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-log-consumer.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-log-anatomy.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-producer-consumer.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-replication.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-metadata-flow.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-stream-processor.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-ktable.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-table-as-stream.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-stateful-process.png">
<meta property="og:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-event-system.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/1-1.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/2.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/3-1.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/4-1-1024x458.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/80061024.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/Snip20180504_56.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/62059279-1024x437.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/1-2-207x300.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/67930538-300x179.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/57646045.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/84999567.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/1-3.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/3-2.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/11-1.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/12-1.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/13-300x103.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/2-1-300x149.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/31.png">
<meta property="og:image" content="http://www.heartthinkdo.com/wp-content/uploads/2018/05/32.png">
<meta property="og:updated_time" content="2019-03-06T08:43:46.783Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kafka">
<meta name="twitter:description" content="Kafka Kafka 是一个分布式的、可水平扩展的、基于发布/订阅模式的、支持容错的消息系统。    1. 概述 1.1. 分布式 1.2. 容错 1.3. 提交日志 1.4. 消息队列 1.5. 为什么要使用消息系统 1.6. Kafka 的关键功能 1.7. Kafka 基本概念 1.8. Kafka 核心 API 1.9. Topic 和日志   2. Kafka 工作原理 3. 持久化">
<meta name="twitter:image" content="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-core-api.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/blog/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/06/13/programming/java/javaweb/distributed/mq/kafka-advanced/">





  <title>Kafka | 张鹏的博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/blog/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">张鹏的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">大道至简，知易行难</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/blog/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/blog/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/blog/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/blog/2018/06/13/programming/java/javaweb/distributed/mq/kafka-advanced/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhang Peng">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/blog/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张鹏的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Kafka</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-13T00:00:00+08:00">
                2018-06-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/分布式/" itemprop="url" rel="index">
                    <span itemprop="name">分布式</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><blockquote>
<p>Kafka 是一个分布式的、可水平扩展的、基于发布/订阅模式的、支持容错的消息系统。</p>
</blockquote>
<!-- TOC depthFrom:2 depthTo:3 -->
<ul>
<li><a href="#1-概述">1. 概述</a><ul>
<li><a href="#11-分布式">1.1. 分布式</a></li>
<li><a href="#12-容错">1.2. 容错</a></li>
<li><a href="#13-提交日志">1.3. 提交日志</a></li>
<li><a href="#14-消息队列">1.4. 消息队列</a></li>
<li><a href="#15-为什么要使用消息系统">1.5. 为什么要使用消息系统</a></li>
<li><a href="#16-kafka-的关键功能">1.6. Kafka 的关键功能</a></li>
<li><a href="#17-kafka-基本概念">1.7. Kafka 基本概念</a></li>
<li><a href="#18-kafka-核心-api">1.8. Kafka 核心 API</a></li>
<li><a href="#19-topic-和日志">1.9. Topic 和日志</a></li>
</ul>
</li>
<li><a href="#2-kafka-工作原理">2. Kafka 工作原理</a></li>
<li><a href="#3-持久化">3. 持久化</a></li>
<li><a href="#4-复制">4. 复制</a></li>
<li><a href="#5-流处理">5. 流处理</a><ul>
<li><a href="#51-无状态处理">5.1. 无状态处理</a></li>
<li><a href="#52-有状态处理">5.2. 有状态处理</a></li>
</ul>
</li>
<li><a href="#6-kafka-应用场景">6. Kafka 应用场景</a></li>
<li><a href="#7-幂等性">7. 幂等性</a><ul>
<li><a href="#71-幂等性实现">7.1. 幂等性实现</a></li>
<li><a href="#72-幂等性的应用实例">7.2. 幂等性的应用实例</a></li>
</ul>
</li>
<li><a href="#8-事务">8. 事务</a><ul>
<li><a href="#81-事务属性理解">8.1. 事务属性理解</a></li>
<li><a href="#82-引入事务目的">8.2. 引入事务目的</a></li>
<li><a href="#83-事务操作的-api">8.3. 事务操作的 API</a></li>
<li><a href="#84-事务属性的应用实例">8.4. 事务属性的应用实例</a></li>
<li><a href="#85-生产者事务的实现">8.5. 生产者事务的实现</a></li>
<li><a href="#86-其他思考">8.6. 其他思考</a></li>
</ul>
</li>
<li><a href="#9-资料">9. 资料</a><ul>
<li><a href="#91-官方资料">9.1. 官方资料</a></li>
<li><a href="#92-第三方资料">9.2. 第三方资料</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><h3 id="1-1-分布式"><a href="#1-1-分布式" class="headerlink" title="1.1. 分布式"></a>1.1. 分布式</h3><p>分布式系统是一个由多个运行机器组成的系统，所有这些机器在一个集群中一起工作，对最终端用户表现为一个节点。</p>
<p>Kafka 的分布式意义在于：它在不同的节点上存储、接收和发送消息。</p>
<h3 id="1-2-容错"><a href="#1-2-容错" class="headerlink" title="1.2. 容错"></a>1.2. 容错</h3><p>分布式系统一般都会设计容错机制，保证集群中几个节点出现故障时，仍能对外提供服务。</p>
<h3 id="1-3-提交日志"><a href="#1-3-提交日志" class="headerlink" title="1.3. 提交日志"></a>1.3. 提交日志</h3><p>提交日志（也称为预写日志，事务日志）是仅支持附加的持久有序数据结构。您不能修改或删除记录。它从左到右读取并保证项目排序。</p>
<p>Kafka 实际上将所有的消息存储到磁盘，并在结构中对它们进行排序，以便利用顺序磁盘读取。</p>
<h3 id="1-4-消息队列"><a href="#1-4-消息队列" class="headerlink" title="1.4. 消息队列"></a>1.4. 消息队列</h3><p>消息队列技术是分布式应用间交换信息的一种技术。消息队列可驻留在内存或磁盘上, 队列存储消息直到它们被应用程序读走。通过消息队列，应用程序可独立地执行–它们不需要知道彼此的位置、或在继续执行前不需要等待接收程序接收此消息。在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。为了管理需要共享的信息，对应用提供公共的信息交换机制是重要的。常用的消息队列技术是 Message Queue。</p>
<p>Message Queue 的通信模式：</p>
<ul>
<li><strong>点对点</strong>：点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。</li>
<li><strong>多点广播</strong>：MQ 适用于不同类型的应用。其中重要的，也是正在发展中的是”多点广播”应用，即能够将消息发送到多个目标站点 (Destination List)。可以使用一条 MQ 指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。MQ 不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，MQ 将消息的一个复制版本和该系统上接收者的名单发送到目标 MQ 系统。目标 MQ 系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。</li>
<li><strong>发布/订阅 (Publish/Subscribe)</strong>：发布/订阅功能使消息的分发可以突破目的队列地理指向的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅功能使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。</li>
<li><strong>集群 (Cluster)</strong>：为了简化点对点通讯模式中的系统配置，MQ 提供 Cluster(集群) 的解决方案。集群类似于一个域 (Domain)，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用集群 (Cluster) 通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性。</li>
</ul>
<h3 id="1-5-为什么要使用消息系统"><a href="#1-5-为什么要使用消息系统" class="headerlink" title="1.5. 为什么要使用消息系统"></a>1.5. 为什么要使用消息系统</h3><ul>
<li>解耦<br>在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</li>
<li>冗余<br>有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</li>
<li>扩展性<br>因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。</li>
<li>灵活性 &amp; 峰值处理能力<br>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</li>
<li>可恢复性<br>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</li>
<li>顺序保证<br>在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka 保证一个 Partition 内的消息的有序性。</li>
<li>缓冲<br>在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。</li>
<li>异步通信<br>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</li>
</ul>
<h3 id="1-6-Kafka-的关键功能"><a href="#1-6-Kafka-的关键功能" class="headerlink" title="1.6. Kafka 的关键功能"></a>1.6. Kafka 的关键功能</h3><ul>
<li>发布和订阅流记录，类似于消息队列或企业级消息系统。</li>
<li>以容错、持久化的方式存储流记录。</li>
<li>处理流记录。</li>
</ul>
<h3 id="1-7-Kafka-基本概念"><a href="#1-7-Kafka-基本概念" class="headerlink" title="1.7. Kafka 基本概念"></a>1.7. Kafka 基本概念</h3><ul>
<li>Kafka 作为一个集群运行在一台或多台可以跨越多个数据中心的服务器上。</li>
<li>Kafka 集群在称为 Topic 的类别中存储记录流。</li>
<li>Kafka 的每个记录由一个键，一个值和一个时间戳组成。</li>
</ul>
<h3 id="1-8-Kafka-核心-API"><a href="#1-8-Kafka-核心-API" class="headerlink" title="1.8. Kafka 核心 API"></a>1.8. Kafka 核心 API</h3><div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-core-api.png" width="400"><br></div>

<ul>
<li>Producer - 允许应用程序将记录流发布到一个或多个 Kafka Topic。</li>
<li>Consumer - 允许应用程序订阅一个或多个 Topic 并处理为他们生成的记录流。</li>
<li>Streams - 允许应用程序充当流处理器，从一个或多个 Topic 中消费输入流，并将输出流生成为一个或多个输出 Topic，从而将输入流有效地转换为输出流。</li>
<li>Connector - 允许构建和运行可重复使用的生产者或消费者，将 Kafka Topic 连接到现有的应用程序或数据系统。例如，连接到关系数据库的连接器可能会捕获对表的每个更改。</li>
</ul>
<p>在 Kafka 中，客户端和服务器之间的通信是采用 TCP 协议方式。</p>
<h3 id="1-9-Topic-和日志"><a href="#1-9-Topic-和日志" class="headerlink" title="1.9. Topic 和日志"></a>1.9. Topic 和日志</h3><p>Topic 是一个目录名，它保存着发布记录。kafka 的 Topic 始终是多订阅者的，也就是说，一个主题可以有零个，一个或多个订阅写入数据的 Consumer。</p>
<p>在 Kafka 中，任意一个 Topic 维护一个 Partition 的日志，类似下图：</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-log-anatomy.png" width="400"><br></div>

<p>每个 Partition 都是一个有序的，不可变的记录序列，不断追加到结构化的提交日志中。Partition 中的记录每个分配一个连续的 id 号，称为偏移量，用于唯一标识 Partition 内的每条记录。</p>
<p>Kafka 集群持久化保存（使用可配置的保留期限）所有发布记录——无论它们是否被消费。例如，如果保留期限被设置为两天，则在记录发布后的两天之内，它都可以被消费，超过时间后将被丢弃以释放空间。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-log-consumer.png" width="400"><br></div>

<p>实际上，保留在每个 Consumer 基础上的唯一元数据是该 Consumer 在日志中的抵消或位置。这个偏移量是由 Consumer 控制的：Consumer 通常会在读取记录时线性地推进其偏移量，但实际上，由于位置由 Consumer 控制，因此它可以按照喜欢的任何顺序消费记录。</p>
<p>这种功能组合意味着 Kafka Consumer 的开销很小——它们的出现对集群和其他 Consumer 没有多少影响。</p>
<p>日志中的 Partition 有多种目的。首先，它们允许日志的大小超出服务器限制的大小。每个单独的 Partition 必须适合承载它的服务器，但是一个主题可能有很多 Partition，因此它可以处理任意数量的数据。其次，它们作为并行的单位。</p>
<h2 id="2-Kafka-工作原理"><a href="#2-Kafka-工作原理" class="headerlink" title="2. Kafka 工作原理"></a>2. Kafka 工作原理</h2><ul>
<li><strong>Broker</strong> - Kafka 集群包含一个或多个服务器，这种服务器被称为 broker。</li>
<li><strong>Topic</strong> - 每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。（物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个 broker 上但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）。</li>
<li><strong>Partition</strong> - Parition 是物理上的概念，每个 Topic 包含一个或多个 Partition。</li>
<li><strong>Producer</strong> - 负责发布消息到 Kafka broker。</li>
<li><strong>Consumer</strong> - 消息消费者，向 Kafka broker 读取消息的客户端。</li>
<li><strong>Consumer Group</strong> - 每个 Consumer 属于一个特定的 Consumer Group（可为每个 Consumer 指定 group name，若不指定 group name 则属于默认的 group）。</li>
</ul>
<p>Producer 将消息（记录）发送到 Kafka 节点（Broker），消息由称为 Consumer 的其他应用程序处理。消息被存储在 Topic 中，并且 Consumer 订阅该主题以接收新消息。</p>
<p>随着 Topic 变得日益庞大，它们会被分割成更小的 Partition 以提高性能和可伸缩性。Kafka 保证 Partition 内的所有消息按照它们出现的顺序排序。区分特定消息的方式是通过它的偏移量，您可以将它看作普通数组索引，每个新消息都会增加一个序列号在一个 Partition 中。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-log-anatomy.png" width="400"><br></div>

<p>Kafka 遵循发布/订阅模式。这意味着 Kafka 不会跟踪 Kafka 读取哪些记录并删除它们，而是将它们存储一段时间（例如一天）或直到满足某个大小阈值。Consumer 自己对 Kafka 进行新的消息调查并说出他们想要阅读的记录。这使得他们可以按照自己的意愿递增/递减偏移量，从而能够重播和重新处理事件。</p>
<p>Kafka 集群持久化保存（使用可配置的保留期限）所有发布记录——无论它们是否被消费。例如，如果保留期限被设置为两天，则在记录发布后的两天之内，它都可以被消费，超过时间后将被丢弃以释放空间。</p>
<p>值得注意的是，Consumer 实际上是内部拥有一个或多个 Consumer 流程的 Consumer 群体。为了避免两个进程读两次相同的消息，每个 Partition 仅与每个组的一个 Consumer 进程相关联。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-producer-consumer.png" width="640"><br></div>

<h2 id="3-持久化"><a href="#3-持久化" class="headerlink" title="3. 持久化"></a>3. 持久化</h2><p>Kafka 实际上将其所有记录存储在磁盘中，并且不会将任何内容保留在 RAM 中。</p>
<ul>
<li>Kafka 有一个将消息分组在一起的协议。它允许网络请求将消息分组在一起以减少网络开销。服务器一气呵成的将消息的数据块持久化并立即获取较大的线性块。</li>
<li>线性读取/写入磁盘速度很快。现代磁盘速度较慢的概念是由于大量的磁盘搜索，这在大型线性操作中不是问题。</li>
<li>所说的线性操作由操作系统通过预读（预取大块数倍）和后写（将小的逻辑写入大物理写入）技术进行了大量优化。</li>
<li>现代操作系统将磁盘缓存在可用 RAM 中。这被称为 pagecache。</li>
<li>由于 Kafka 在整个流程（生产者 -&gt; 经纪 -&gt; 消费者）中以标准化的二进制格式存储未修改的消息，所以它可以利用零拷贝优化。这就是操作系统将数据从页面缓存直接复制到套接字时，完全绕过了 Kafka 经纪人应用程序。</li>
</ul>
<p>所有这些优化都允许 Kafka 以接近网络速度传递消息。</p>
<h2 id="4-复制"><a href="#4-复制" class="headerlink" title="4. 复制"></a>4. 复制</h2><p>分区数据在多个代理中复制，以便在一个代理死亡的情况下保存数据。</p>
<p>在任何时候，一个代理“拥有”一个分区，并且是应用程序通过该分区读写数据的节点。这被称为分区领导。它将它收到的数据复制到 N 个其他代理（称为追随者）。他们也存储数据，并准备在领导者节点死亡的情况下取代领导者。这就是典型的一主多从模式。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-replication.png" width="640"><br></div>

<p>生产者/消费者如何知道分区的领导者是谁？</p>
<p>对于生产者/消费者来说，从一个分区写入/读取，他们需要知道它的领导者，对吧？这些信息需要从某处获得。Kafka 将这种元数据存储在一个名为 Zookeeper 的服务中。</p>
<p>生产者和消费者都和 Zookeeper 连接并通信。Kafka 一直在摆脱这种耦合，自 0.8 和 0.9 版分别开始，客户端直接从 Kafka 经纪人那里获取元数据信息，他们自己与 Zookeeper 交谈。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-metadata-flow.png" width="640"><br></div>

<h2 id="5-流处理"><a href="#5-流处理" class="headerlink" title="5. 流处理"></a>5. 流处理</h2><p>在 Kafka 中，流处理器是任何需要从输入主题中持续输入数据流，对该输入执行一些处理并生成输出主题的数据流（或外部服务，数据库，垃圾桶，无论哪里真的……）</p>
<p>可以直接使用生产者/消费者 API 进行简单处理，但对于更复杂的转换（如将流连接在一起），Kafka 提供了一个集成的 Streams API 库。</p>
<p>此 API 旨在用于您自己的代码库中，它不在代理上运行。它与消费者 API 类似，可帮助您扩展多个应用程序的流处理工作（类似于消费者群体）。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-stream-processor.png" width="640"><br></div>

<h3 id="5-1-无状态处理"><a href="#5-1-无状态处理" class="headerlink" title="5.1. 无状态处理"></a>5.1. 无状态处理</h3><p>流的无状态处理是确定性处理，不依赖于任何外部。你知道，对于任何给定的数据，你将总是产生独立于其他任何东西的相同输出。</p>
<p>一个流可以被解释为一个表，一个表可以被解释为一个流。</p>
<p>流可以被解释为数据的一系列更新，其中聚合是表的最终结果。</p>
<p>如果您看看如何实现同步数据库复制，您会发现它是通过所谓的流式复制，其中表中的每个更改都发送到副本服务器。</p>
<p>Kafka 流可以用同样的方式解释 - 当从最终状态积累时的事件。这样的流聚合被保存在本地的 RocksDB 中（默认情况下），被称为 KTable。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-ktable.png" width="640"><br></div>

<p>可以将表格视为流中每个键的最新值的快照。以同样的方式，流记录可以产生一个表，表更新可以产生一个更新日志流。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-table-as-stream.png" width="640"><br></div>

<h3 id="5-2-有状态处理"><a href="#5-2-有状态处理" class="headerlink" title="5.2. 有状态处理"></a>5.2. 有状态处理</h3><p>一些简单的操作，如 map() 或 filter() 是无状态的，并且不要求您保留有关处理的任何数据。但是，在现实生活中，你要做的大多数操作都是有状态的（例如 count()），因此需要存储当前的累积状态。</p>
<p>维护流处理器上的状态的问题是流处理器可能会失败！你需要在哪里保持这个状态才能容错？</p>
<p>一种天真的做法是简单地将所有状态存储在远程数据库中，并通过网络连接到该存储。问题在于没有数据的地方和大量的网络往返，这两者都会显著减慢你的应用程序。一个更微妙但重要的问题是，您的流处理作业的正常运行时间将与远程数据库紧密耦合，并且作业不会自成体系（数据库中来自另一个团队的更改可能会破坏您的处理过程）。</p>
<p>那么更好的方法是什么？</p>
<p>回想一下表和流的双重性。这使我们能够将数据流转换为与我们的处理共处一地的表格。它还为我们提供了处理容错的机制 - 通过将流存储在 Kafka 代理中。</p>
<p>流处理器可以将其状态保存在本地表（例如 RocksDB）中，该表将从输入流更新（可能是某种任意转换之后）。当进程失败时，它可以通过重放流来恢复其数据。</p>
<p>您甚至可以让远程数据库成为流的生产者，从而有效地广播更新日志，以便在本地重建表。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-stateful-process.png" width="640"><br></div>

<h2 id="6-Kafka-应用场景"><a href="#6-Kafka-应用场景" class="headerlink" title="6. Kafka 应用场景"></a>6. Kafka 应用场景</h2><ul>
<li>构建实时的流数据管道，在系统或应用间获取可靠数据。</li>
<li>构建实时的流应用程序，用于转换或响应数据流。</li>
</ul>
<p>正如我们已经介绍的那样，Kafka 允许您将大量消息通过集中介质存储并存储，而不用担心性能或数据丢失等问题。</p>
<p>这意味着它非常适合用作系统架构的核心，充当连接不同应用程序的集中介质。 Kafka 可以成为事件驱动架构的核心部分，并允许您真正将应用程序彼此分离。</p>
<div align="center"><br><img src="https://raw.githubusercontent.com/dunwu/JavaWeb/master/images/distributed/mq/kafka/kafka-event-system.png" width="640"><br></div>

<p>Kafka 允许您轻松分离不同（微）服务之间的通信。利用 Streams API，现在比以往更容易编写业务逻辑，丰富了 Kafka 主题数据以便服务消费。</p>
<h2 id="7-幂等性"><a href="#7-幂等性" class="headerlink" title="7. 幂等性"></a>7. 幂等性</h2><p>幂等性引入目的：生产者重复生产消息。生产者进行 retry 会产生重试时，会重复产生消息。有了幂等性之后，在进行 retry 重试时，只会生成一个消息。</p>
<h3 id="7-1-幂等性实现"><a href="#7-1-幂等性实现" class="headerlink" title="7.1. 幂等性实现"></a>7.1. 幂等性实现</h3><h4 id="7-1-1-PID-和-Sequence-Number"><a href="#7-1-1-PID-和-Sequence-Number" class="headerlink" title="7.1.1. PID 和 Sequence Number"></a>7.1.1. PID 和 Sequence Number</h4><p>为了实现 Producer 的幂等性，Kafka 引入了 Producer ID（即 PID）和 Sequence Number。</p>
<ul>
<li>PID。每个新的 Producer 在初始化的时候会被分配一个唯一的 PID，这个 PID 对用户是不可见的。</li>
<li>Sequence Numbler。（对于每个 PID，该 Producer 发送数据的每个&lt;Topic, Partition&gt;都对应一个从 0 开始单调递增的 Sequence Number。</li>
</ul>
<p>Broker 端在缓存中保存了这 seq number，对于接收的每条消息，如果其序号比 Broker 缓存中序号大于 1 则接受它，否则将其丢弃。这样就可以实现了消息重复提交了。但是，只能保证单个 Producer 对于同一个&lt;Topic, Partition&gt;的 Exactly Once 语义。不能保证同一个 Producer 一个 topic 不同的 partion 幂等。</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/1-1.png"></div><br></p>
<p>实现幂等之后</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/2.png"></div><br></p>
<h4 id="7-1-2-生成-PID-的流程"><a href="#7-1-2-生成-PID-的流程" class="headerlink" title="7.1.2. 生成 PID 的流程"></a>7.1.2. 生成 PID 的流程</h4><p>在执行创建事务时，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br></pre></td></tr></table></figure>
<p>会创建一个 Sender，并启动线程，执行如下 run 方法，在 maybeWaitForProducerId()中生成一个 producerId，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">====================================</span><br><span class="line">类名：Sender</span><br><span class="line">====================================</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                 ........</span><br><span class="line">                <span class="keyword">if</span> (!transactionManager.isTransactional()) &#123;</span><br><span class="line">                    <span class="comment">// 为idempotent producer生成一个producer id</span></span><br><span class="line">                    maybeWaitForProducerId();</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (transactionManager.hasUnresolvedSequences() &amp;&amp; !transactionManager.hasFatalError()) &#123;</span><br><span class="line">                   ........</span><br></pre></td></tr></table></figure>
<h3 id="7-2-幂等性的应用实例"><a href="#7-2-幂等性的应用实例" class="headerlink" title="7.2. 幂等性的应用实例"></a>7.2. 幂等性的应用实例</h3><p>（1）配置属性</p>
<p>需要设置：</p>
<ul>
<li>enable.idempotence，需要设置为 ture,此时就会默认把 acks 设置为 all，所以不需要再设置 acks 属性了。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Producer <span class="title">buildIdempotProducer</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create instance for properties to access producer configs</span></span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// bootstrap.servers是Kafka集群的IP地址。多个时,使用逗号隔开</span></span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"enable.idempotence"</span>,<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//If the request fails, the producer can automatically retry,</span></span><br><span class="line">    props.put(<span class="string">"retries"</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Reduce the no of requests less than 0</span></span><br><span class="line">    props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//The buffer.memory controls the total amount of memory available to the producer for buffering.</span></span><br><span class="line">    props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Kafka消息是以键值对的形式发送,需要设置key和value类型序列化器</span></span><br><span class="line">    props.put(<span class="string">"key.serializer"</span>,</span><br><span class="line">            <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"value.serializer"</span>,</span><br><span class="line">            <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">    Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> producer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）发送消息</p>
<p>跟一般生产者一样，如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">produceIdempotMessage</span><span class="params">(String topic, String message)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建Producer</span></span><br><span class="line">    Producer producer = buildIdempotProducer();</span><br><span class="line">    <span class="comment">// 发送消息</span></span><br><span class="line">    producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(topic, message));</span><br><span class="line">    producer.flush();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时，因为我们并没有配置 transaction.id 属性，所以不能使用事务相关 API，如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">producer.initTransactions();</span><br></pre></td></tr></table></figure>
<p>否则会出现如下错误：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread “main” java.lang.IllegalStateException: Transactional method invoked on a non-transactional producer.</span><br><span class="line">    at org.apache.kafka.clients.producer.internals.TransactionManager.ensureTransactional(TransactionManager.java:<span class="number">777</span>)</span><br><span class="line">    at org.apache.kafka.clients.producer.internals.TransactionManager.initializeTransactions(TransactionManager.java:<span class="number">202</span>)</span><br><span class="line">    at org.apache.kafka.clients.producer.KafkaProducer.initTransactions(KafkaProducer.java:<span class="number">544</span>)</span><br></pre></td></tr></table></figure>
<h2 id="8-事务"><a href="#8-事务" class="headerlink" title="8. 事务"></a>8. 事务</h2><h3 id="8-1-事务属性理解"><a href="#8-1-事务属性理解" class="headerlink" title="8.1. 事务属性理解"></a>8.1. 事务属性理解</h3><p>事务属性是 2017 年 Kafka 0.11.0.0 引入的新特性。类似于数据库事务，只是这里的数据源是 Kafka，<strong>kafka 事务属性是指一系列的生产者生产消息和消费者提交偏移量的操作在一个事务，或者说是是一个原子操作），同时成功或者失败</strong>。</p>
<p>注意：在理解消息的事务时，一直处于一个错误理解就是如下代码中，把操作 db 的业务逻辑跟操作消息当成是一个事务。其实这个是有问题的，操作 DB 数据库的数据源是 DB，消息数据源是 kfaka，这是完全不同两个数据，一种数据源（如 mysql，kafka）对应一个事务，所以它们是两个独立的事务：kafka 事务指 kafka 一系列 生产、消费消息等操作组成一个原子操作；db 事务是指操作数据库的一系列增删改操作组成一个原子操作。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span>  <span class="title">kakfa_in_tranction</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 1.kafa的操作：读取消息或者生产消息</span></span><br><span class="line">    kafkaOperation();</span><br><span class="line">    <span class="comment">// 2.db操作</span></span><br><span class="line">    dbOperation();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="8-2-引入事务目的"><a href="#8-2-引入事务目的" class="headerlink" title="8.2. 引入事务目的"></a>8.2. 引入事务目的</h3><p>在事务属性之前先引入了生产者幂等性，它的作用为：</p>
<ul>
<li>生产者多次发送消息可以封装成一个原子操作，要么都成功，要么失败</li>
<li>consumer-transform-producer 模式下，因为消费者提交偏移量出现问题，导致在重复消费消息时，生产者重复生产消息。需要将这个模式下消费者提交偏移量操作和生产者一系列生成消息的操作封装成一个原子操作。</li>
</ul>
<p><strong>消费者提交偏移量导致重复消费消息的场景</strong>：消费者在消费消息完成提交便宜量 o2 之前挂掉了（假设它最近提交的偏移量是 o1），此时执行再均衡时，其它消费者会重复消费消息(o1 到 o2 之间的消息）。</p>
<h3 id="8-3-事务操作的-API"><a href="#8-3-事务操作的-API" class="headerlink" title="8.3. 事务操作的 API"></a>8.3. 事务操作的 API</h3><p>producer 提供了 initTransactions, beginTransaction, sendOffsets, commitTransaction, abortTransaction 五个事务方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 初始化事务。需要注意的有：</span></span><br><span class="line"><span class="comment"> * 1、前提</span></span><br><span class="line"><span class="comment"> * 需要保证transation.id属性被配置。</span></span><br><span class="line"><span class="comment"> * 2、这个方法执行逻辑是：</span></span><br><span class="line"><span class="comment"> *   （1）Ensures any transactions initiated by previous instances of the producer with the same</span></span><br><span class="line"><span class="comment"> *      transactional.id are completed. If the previous instance had failed with a transaction in</span></span><br><span class="line"><span class="comment"> *      progress, it will be aborted. If the last transaction had begun completion,</span></span><br><span class="line"><span class="comment"> *      but not yet finished, this method awaits its completion.</span></span><br><span class="line"><span class="comment"> *    （2）Gets the internal producer id and epoch, used in all future transactional</span></span><br><span class="line"><span class="comment"> *      messages issued by the producer.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initTransactions</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 开启事务</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException </span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 为消费者提供的在事务内提交偏移量的操作</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendOffsetsToTransaction</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     String consumerGroupId)</span> <span class="keyword">throws</span> ProducerFencedException </span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 提交事务</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commitTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 放弃事务，类似回滚事务的操作</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">abortTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException </span>;</span><br></pre></td></tr></table></figure>
<h3 id="8-4-事务属性的应用实例"><a href="#8-4-事务属性的应用实例" class="headerlink" title="8.4. 事务属性的应用实例"></a>8.4. 事务属性的应用实例</h3><p>在一个原子操作中，根据包含的操作类型，可以分为三种情况，<strong>前两种情况是事务引入的场景</strong>，最后一种情况没有使用价值。</p>
<p>只有 Producer 生产消息；</p>
<p>消费消息和生产消息并存，<strong>这个是事务场景中最常用的情况</strong>，就是我们常说的“consume-transform-produce ”模式</p>
<p>只有 consumer 消费消息，这种操作其实没有什么意义，跟使用手动提交效果一样，而且也不是事务属性引入的目的，所以一般不会使用这种情况</p>
<h4 id="8-4-1-相关属性配置"><a href="#8-4-1-相关属性配置" class="headerlink" title="8.4.1. 相关属性配置"></a>8.4.1. 相关属性配置</h4><p>使用 kafka 的事务 api 时的一些注意事项：</p>
<ul>
<li>需要消费者的自动模式设置为 false,并且不能子再手动的进行执行 consumer#commitSync 或者 consumer#commitAsyc</li>
<li>生产者配置 transaction.id 属性</li>
<li>生产者不需要再配置 enable.idempotence，因为如果配置了 transaction.id，则此时 enable.idempotence 会被设置为 true</li>
<li>消费者需要配置 Isolation.level。在 consume-trnasform-produce 模式下使用事务时，必须设置为 READ_COMMITTED。</li>
</ul>
<h4 id="8-4-2-只有写"><a href="#8-4-2-只有写" class="headerlink" title="8.4.2. 只有写"></a>8.4.2. 只有写</h4><p>创建一个事务，在这个事务操作中，只有生成消息操作。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 在一个事务只有生产消息操作</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onlyProduceInTransaction</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Producer producer = buildProducer();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.初始化事务</span></span><br><span class="line">    producer.initTransactions();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.开启事务</span></span><br><span class="line">    producer.beginTransaction();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 3.kafka写操作集合</span></span><br><span class="line">        <span class="comment">// 3.1 do业务逻辑</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.2 发送消息</span></span><br><span class="line">        producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"test"</span>, <span class="string">"transaction-data-1"</span>));</span><br><span class="line"></span><br><span class="line">        producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"test"</span>, <span class="string">"transaction-data-2"</span>));</span><br><span class="line">        <span class="comment">// 3.3 do其他业务逻辑,还可以发送其他topic的消息。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.事务提交</span></span><br><span class="line">        producer.commitTransaction();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="comment">// 5.放弃事务</span></span><br><span class="line">        producer.abortTransaction();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>创建生产者，代码如下,需要:</p>
<ul>
<li>配置 transactional.id 属性</li>
<li>配置 enable.idempotence 属性</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 需要:</span></span><br><span class="line"><span class="comment"> * 1、设置transactional.id</span></span><br><span class="line"><span class="comment"> * 2、设置enable.idempotence</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Producer <span class="title">buildProducer</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create instance for properties to access producer configs</span></span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// bootstrap.servers是Kafka集群的IP地址。多个时,使用逗号隔开</span></span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置事务id</span></span><br><span class="line">    props.put(<span class="string">"transactional.id"</span>, <span class="string">"first-transactional"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置幂等性</span></span><br><span class="line">    props.put(<span class="string">"enable.idempotence"</span>,<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Set acknowledgements for producer requests.</span></span><br><span class="line">    props.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//If the request fails, the producer can automatically retry,</span></span><br><span class="line">    props.put(<span class="string">"retries"</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Specify buffer size in config,这里不进行设置这个属性,如果设置了,还需要执行producer.flush()来把缓存中消息发送出去</span></span><br><span class="line">    <span class="comment">//props.put("batch.size", 16384);</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//Reduce the no of requests less than 0</span></span><br><span class="line">    props.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//The buffer.memory controls the total amount of memory available to the producer for buffering.</span></span><br><span class="line">    props.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Kafka消息是以键值对的形式发送,需要设置key和value类型序列化器</span></span><br><span class="line">    props.put(<span class="string">"key.serializer"</span>,</span><br><span class="line">            <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">    props.put(<span class="string">"value.serializer"</span>,</span><br><span class="line">            <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> producer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="8-4-3-消费-生产并存（consume-transform-produce）"><a href="#8-4-3-消费-生产并存（consume-transform-produce）" class="headerlink" title="8.4.3. 消费-生产并存（consume-transform-produce）"></a>8.4.3. 消费-生产并存（consume-transform-produce）</h4><p>在一个事务中，既有生产消息操作又有消费消息操作，即常说的 Consume-tansform-produce 模式。如下实例代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 在一个事务内,即有生产消息又有消费消息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">consumeTransferProduce</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 1.构建上产者</span></span><br><span class="line">    Producer producer = buildProducer();</span><br><span class="line">    <span class="comment">// 2.初始化事务(生成productId),对于一个生产者,只能执行一次初始化事务操作</span></span><br><span class="line">    producer.initTransactions();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.构建消费者和订阅主题</span></span><br><span class="line">    Consumer consumer = buildConsumer();</span><br><span class="line">    consumer.subscribe(Arrays.asList(<span class="string">"test"</span>));</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        <span class="comment">// 4.开启事务</span></span><br><span class="line">        producer.beginTransaction();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5.1 接受消息</span></span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 5.2 do业务逻辑;</span></span><br><span class="line">            System.out.println(<span class="string">"customer Message---"</span>);</span><br><span class="line">            Map&lt;TopicPartition, OffsetAndMetadata&gt; commits = Maps.newHashMap();</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                <span class="comment">// 5.2.1 读取消息,并处理消息。print the offset,key and value for the consumer records.</span></span><br><span class="line">                System.out.printf(<span class="string">"offset = %d, key = %s, value = %s\n"</span>,</span><br><span class="line">                        record.offset(), record.key(), record.value());</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 5.2.2 记录提交的偏移量</span></span><br><span class="line">                commits.put(<span class="keyword">new</span> TopicPartition(record.topic(), record.partition()),</span><br><span class="line">                        <span class="keyword">new</span> OffsetAndMetadata(record.offset()));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                <span class="comment">// 6.生产新的消息。比如外卖订单状态的消息,如果订单成功,则需要发送跟商家结转消息或者派送员的提成消息</span></span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"test"</span>, <span class="string">"data2"</span>));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 7.提交偏移量</span></span><br><span class="line">            producer.sendOffsetsToTransaction(commits, <span class="string">"group0323"</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 8.事务提交</span></span><br><span class="line">            producer.commitTransaction();</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// 7.放弃事务</span></span><br><span class="line">            producer.abortTransaction();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>创建消费者代码，需要：</p>
<ul>
<li>将配置中的自动提交属性（auto.commit）进行关闭</li>
<li>而且在代码里面也不能使用手动提交 commitSync( )或者 commitAsync( )</li>
<li>设置 isolation.level</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 需要:</span></span><br><span class="line"><span class="comment"> * 1、关闭自动提交 enable.auto.commit</span></span><br><span class="line"><span class="comment"> * 2、isolation.level为</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Consumer <span class="title">buildConsumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    <span class="comment">// bootstrap.servers是Kafka集群的IP地址。多个时,使用逗号隔开</span></span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line">    <span class="comment">// 消费者群组</span></span><br><span class="line">    props.put(<span class="string">"group.id"</span>, <span class="string">"group0323"</span>);</span><br><span class="line">    <span class="comment">// 设置隔离级别</span></span><br><span class="line">    props.put(<span class="string">"isolation.level"</span>,<span class="string">"read_committed"</span>);</span><br><span class="line">    <span class="comment">// 关闭自动提交</span></span><br><span class="line">    props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>);</span><br><span class="line">    props.put(<span class="string">"session.timeout.ms"</span>, <span class="string">"30000"</span>);</span><br><span class="line">    props.put(<span class="string">"key.deserializer"</span>,</span><br><span class="line">            <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    props.put(<span class="string">"value.deserializer"</span>,</span><br><span class="line">            <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer</span><br><span class="line">            &lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> consumer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="8-4-4-只有读"><a href="#8-4-4-只有读" class="headerlink" title="8.4.4. 只有读"></a>8.4.4. 只有读</h4><p>创建一个事务，在这个事务操作中，只有生成消息操作，如下代码。这种操作其实没有什么意义，跟使用手动提交效果一样，无法保证消费消息操作和提交偏移量操作在一个事务。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 在一个事务只有消息操作</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onlyConsumeInTransaction</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Producer producer = buildProducer();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.初始化事务</span></span><br><span class="line">    producer.initTransactions();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.开启事务</span></span><br><span class="line">    producer.beginTransaction();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.kafka读消息的操作集合</span></span><br><span class="line">    Consumer consumer = buildConsumer();</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        <span class="comment">// 3.1 接受消息</span></span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 3.2 do业务逻辑;</span></span><br><span class="line">            System.out.println(<span class="string">"customer Message---"</span>);</span><br><span class="line">            Map&lt;TopicPartition, OffsetAndMetadata&gt; commits = Maps.newHashMap();</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                <span class="comment">// 3.2.1 处理消息 print the offset,key and value for the consumer records.</span></span><br><span class="line">                System.out.printf(<span class="string">"offset = %d, key = %s, value = %s\n"</span>,</span><br><span class="line">                        record.offset(), record.key(), record.value());</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 3.2.2 记录提交偏移量</span></span><br><span class="line">                commits.put(<span class="keyword">new</span> TopicPartition(record.topic(), record.partition()),</span><br><span class="line">                        <span class="keyword">new</span> OffsetAndMetadata(record.offset()));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 4.提交偏移量</span></span><br><span class="line">            producer.sendOffsetsToTransaction(commits, <span class="string">"group0323"</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 5.事务提交</span></span><br><span class="line">            producer.commitTransaction();</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// 6.放弃事务</span></span><br><span class="line">            producer.abortTransaction();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="8-5-生产者事务的实现"><a href="#8-5-生产者事务的实现" class="headerlink" title="8.5. 生产者事务的实现"></a>8.5. 生产者事务的实现</h3><h4 id="8-5-1-相关配置"><a href="#8-5-1-相关配置" class="headerlink" title="8.5.1. 相关配置"></a>8.5.1. 相关配置</h4><h4 id="8-5-2-幂等性和事务性的关系"><a href="#8-5-2-幂等性和事务性的关系" class="headerlink" title="8.5.2. 幂等性和事务性的关系"></a>8.5.2. 幂等性和事务性的关系</h4><h5 id="两者关系"><a href="#两者关系" class="headerlink" title="两者关系"></a>两者关系</h5><p>事务属性实现前提是幂等性，即在配置事务属性 transaction id 时，必须还得配置幂等性；但是幂等性是可以独立使用的，不需要依赖事务属性。</p>
<ul>
<li>幂等性引入了 Porducer ID</li>
<li>事务属性引入了 Transaction Id 属性。、</li>
</ul>
<p>设置</p>
<ul>
<li>enable.idempotence = true，transactional.id 不设置：只支持幂等性。</li>
<li>enable.idempotence = true，transactional.id 设置：支持事务属性和幂等性</li>
<li>enable.idempotence = false，transactional.id 不设置：没有事务属性和幂等性的 kafka</li>
<li>enable.idempotence = false，transactional.id 设置：无法获取到 PID，此时会报错</li>
</ul>
<h5 id="tranaction-id-、productid-和-epoch"><a href="#tranaction-id-、productid-和-epoch" class="headerlink" title="tranaction id 、productid 和 epoch"></a>tranaction id 、productid 和 epoch</h5><p><strong>一个 app 有一个 tid，同一个应用的不同实例 PID 是一样的，只是 epoch 的值不同</strong>。如：</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/3-1.png"></div><br></p>
<p>同一份代码运行两个实例，分步执行如下：<em>在实例 1 没有进行提交事务前，开始执行实例 2 的初始化事务</em></p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/4-1-1024x458.png"></div><br></p>
<p><strong>step1 实例 1-初始化事务</strong>。的打印出对应 productId 和 epoch，信息如下：</p>
<p>[2018-04-21 20:56:23,106] INFO [TransactionCoordinator id=0] Initialized transactionalId first-transactional with producerId 8000 and producer epoch 123 on partition __transaction_state-12 (kafka.coordinator.transaction.TransactionCoordinator)</p>
<p><strong>step2 实例 1-发送消息。</strong></p>
<p><strong>step3 实例 2-初始化事务</strong>。初始化事务时的打印出对应 productId 和 epoch，信息如下：</p>
<p>18-04-21 20:56:48,373] INFO [TransactionCoordinator id=0] Initialized transactionalId first-transactional with producerId 8000 and producer epoch 124 on partition __transaction_state-12 (kafka.coordinator.transaction.TransactionCoordinator)</p>
<p><strong>step4 实例 1-提交事务</strong>，此时报错</p>
<p>org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer’s transaction has been expired by the broker.</p>
<p><strong>step5 实例 2-提交事务</strong></p>
<p>为了避免这种错误，同一个事务 ID，只有保证如下顺序 epch 小 producer 执行 init-transaction 和 committransaction，然后 epoch 较大的 procuder 才能开始执行 init-transaction 和 commit-transaction，如下顺序：</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/80061024.png"></div><br></p>
<p>有了 transactionId 后，Kafka 可保证：</p>
<ul>
<li>跨 Session 的数据幂等发送。当具有相同 Transaction ID 的新的 Producer 实例被创建且工作时，旧的且拥有相同 Transaction ID 的 Producer 将不再工作【上面的实例可以验证】。kafka 保证了关联同一个事务的所有 producer（一个应用有多个实例）必须按照顺序初始化事务、和提交事务，否则就会有问题，这保证了同一事务 ID 中消息是有序的（不同实例得按顺序创建事务和提交事务）。</li>
</ul>
<h4 id="8-5-3-事务最佳实践-单实例的事务性"><a href="#8-5-3-事务最佳实践-单实例的事务性" class="headerlink" title="8.5.3. 事务最佳实践-单实例的事务性"></a>8.5.3. 事务最佳实践-单实例的事务性</h4><p>通过上面实例中可以看到 kafka 是跨 Session 的数据幂等发送，即如果应用部署多个实例时常会遇到上面的问题“<em>org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer’s transaction has been expired by the broker</em>.”，必须保证这些实例生产者的提交事务顺序和创建顺序保持一致才可以，否则就无法成功。其实，在实践中，我们更多的是<strong>如何实现对应用单实例的事务性</strong>。可以通过 spring-kafaka 实现思路来学习，即<strong>每次创建生产者都设置一个不同的 transactionId 的值</strong>，如下代码：</p>
<p>在 spring-kafka 中，对于一个线程创建一个 producer，事务提交之后，还会关闭这个 producer 并清除，后续同一个线程或者新的线程重新执行事务时，此时就会重新创建 producer。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">====================================</span><br><span class="line">类名：ProducerFactoryUtils</span><br><span class="line">====================================</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Obtain a Producer that is synchronized with the current transaction, if any.</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> producerFactory the ConnectionFactory to obtain a Channel for</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> &lt;K&gt; the key type.</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> &lt;V&gt; the value type.</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> the resource holder.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;K, V&gt; <span class="function">KafkaResourceHolder&lt;K, V&gt; <span class="title">getTransactionalResourceHolder</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> ProducerFactory&lt;K, V&gt; producerFactory)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Assert.notNull(producerFactory, <span class="string">"ProducerFactory must not be null"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.对于每一个线程会生成一个唯一key，然后根据key去查找resourceHolder</span></span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    KafkaResourceHolder&lt;K, V&gt; resourceHolder = (KafkaResourceHolder&lt;K, V&gt;) TransactionSynchronizationManager</span><br><span class="line">            .getResource(producerFactory);</span><br><span class="line">    <span class="keyword">if</span> (resourceHolder == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 2.创建一个消费者</span></span><br><span class="line">        Producer&lt;K, V&gt; producer = producerFactory.createProducer();</span><br><span class="line">        <span class="comment">// 3.开启事务</span></span><br><span class="line">        producer.beginTransaction();</span><br><span class="line">        resourceHolder = <span class="keyword">new</span> KafkaResourceHolder&lt;K, V&gt;(producer);</span><br><span class="line">        bindResourceToTransaction(resourceHolder, producerFactory);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> resourceHolder;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>创建消费者代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">====================================</span><br><span class="line">类名：DefaultKafkaProducerFactory</span><br><span class="line">====================================</span><br><span class="line"><span class="function"><span class="keyword">protected</span> Producer&lt;K, V&gt; <span class="title">createTransactionalProducer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Producer&lt;K, V&gt; producer = <span class="keyword">this</span>.cache.poll();</span><br><span class="line">    <span class="keyword">if</span> (producer == <span class="keyword">null</span>) &#123;</span><br><span class="line">        Map&lt;String, Object&gt; configs = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="keyword">this</span>.configs);</span><br><span class="line">        <span class="comment">// 对于每一次生成producer时，都设置一个不同的transactionId</span></span><br><span class="line">        configs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,</span><br><span class="line">                <span class="keyword">this</span>.transactionIdPrefix + <span class="keyword">this</span>.transactionIdSuffix.getAndIncrement());</span><br><span class="line">        producer = <span class="keyword">new</span> KafkaProducer&lt;K, V&gt;(configs, <span class="keyword">this</span>.keySerializer, <span class="keyword">this</span>.valueSerializer);</span><br><span class="line">        <span class="comment">// 1.初始化话事务。</span></span><br><span class="line">        producer.initTransactions();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CloseSafeProducer&lt;K, V&gt;(producer, <span class="keyword">this</span>.cache);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> producer;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="8-5-4-Consume-transform-Produce-的流程"><a href="#8-5-4-Consume-transform-Produce-的流程" class="headerlink" title="8.5.4. Consume-transform-Produce 的流程"></a>8.5.4. Consume-transform-Produce 的流程</h4><p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/Snip20180504_56.png"></div><br></p>
<p><strong>流程 1</strong> <strong>：</strong>查找 Tranaction Corordinator。</p>
<p>Producer 向任意一个 brokers 发送 FindCoordinatorRequest 请求来获取 Transaction Coordinator 的地址。</p>
<p><strong>流程 2：</strong>初始化事务 initTransaction</p>
<p>Producer 发送 InitpidRequest 给事务协调器，获取一个 Pid<strong>。InitpidRequest 的处理过程是同步阻塞的，一旦该调用正确返回，Producer 就可以开始新的事务</strong>。TranactionalId 通过 InitpidRequest 发送给 Tranciton Corordinator，然后在 Tranaciton Log 中记录这&lt;TranacionalId,pid&gt;的映射关系。除了返回 PID 之外，还具有如下功能：</p>
<ul>
<li>对 PID 对应的 epoch 进行递增，这样可以保证同一个 app 的不同实例对应的 PID 是一样的，但是 epoch 是不同的。</li>
<li>回滚之前的 Producer 未完成的事务（如果有）。</li>
</ul>
<p><strong>流程 3：</strong> 开始事务 beginTransaction</p>
<p>执行 Producer 的 beginTransacion()，它的作用是 Producer 在本地记录下这个 transaction 的状态为开始状态。</p>
<p>注意：这个操作并没有通知 Transaction Coordinator。</p>
<p><strong>流程 4：</strong> Consume-transform-produce loop</p>
<p><strong>流程 4.0：</strong> 通过 Consumtor 消费消息，处理业务逻辑</p>
<p><strong>流程 4.1：</strong> producer 向 TransactionCordinantro 发送 AddPartitionsToTxnRequest</p>
<p>在 producer 执行 send 操作时，如果是第一次给&lt;topic,partion&gt;发送数据，此时会向 Trasaction Corrdinator 发送一个 AddPartitionsToTxnRequest 请求，Transaction Corrdinator 会在 transaction log 中记录下 tranasactionId 和&lt;topic,partion&gt;一个映射关系，并将状态改为 begin。AddPartionsToTxnRequest 的数据结构如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">AddPartitionsToTxnRequest =&gt; TransactionalId PID Epoch [Topic [Partition]]</span><br><span class="line"> TransactionalId =&gt; string</span><br><span class="line"> PID =&gt; int64</span><br><span class="line"> Epoch =&gt; int16</span><br><span class="line"> Topic =&gt; string</span><br><span class="line"> Partition =&gt; int32</span><br></pre></td></tr></table></figure>
<p><strong>流程 4.2：</strong> producer#send 发送 ProduceRequst</p>
<p>生产者发送数据，虽然没有还没有执行 commit 或者 absrot，但是此时消息已经保存到 kafka 上，可以参考如下图断点位置处，此时已经可以查看到消息了，而且即使后面执行 abort，消息也不会删除，只是更改状态字段标识消息为 abort 状态。</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/62059279-1024x437.png"></div><br></p>
<p><strong>流程 4.3：</strong> AddOffsetCommitsToTxnRequest</p>
<p>Producer 通过 KafkaProducer.sendOffsetsToTransaction 向事务协调器器发送一个 AddOffesetCommitsToTxnRequests：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">AddOffsetsToTxnRequest =&gt; TransactionalId PID Epoch ConsumerGroupID</span><br><span class="line"> TransactionalId =&gt; string</span><br><span class="line"> PID =&gt; int64</span><br><span class="line"> Epoch =&gt; int16</span><br><span class="line"> ConsumerGroupID =&gt; string</span><br></pre></td></tr></table></figure>
<p>在执行事务提交时，可以根据 ConsumerGroupID 来推断_customer_offsets 主题中相应的 TopicPartions 信息。这样在</p>
<p><strong>流程 4.4:</strong> TxnOffsetCommitRequest</p>
<p>Producer 通过 KafkaProducer.sendOffsetsToTransaction 还会向消费者协调器 Cosumer Corrdinator 发送一个 TxnOffsetCommitRequest，在主题_consumer_offsets 中保存消费者的偏移量信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">TxnOffsetCommitRequest   =&gt; ConsumerGroupID</span><br><span class="line">                            PID</span><br><span class="line">                            Epoch</span><br><span class="line">                            RetentionTime</span><br><span class="line">                            OffsetAndMetadata</span><br><span class="line">  ConsumerGroupID =&gt; string</span><br><span class="line">  PID =&gt; int64</span><br><span class="line">  Epoch =&gt; int32</span><br><span class="line">  RetentionTime =&gt; int64</span><br><span class="line">  OffsetAndMetadata =&gt; [TopicName [Partition Offset Metadata]]</span><br><span class="line">    TopicName =&gt; string</span><br><span class="line">    Partition =&gt; int32</span><br><span class="line">    Offset =&gt; int64</span><br><span class="line">    Metadata =&gt; string</span><br></pre></td></tr></table></figure>
<p><strong>流程 5：</strong> 事务提交和事务终结(放弃事务)</p>
<p>通过生产者的 commitTransaction 或 abortTransaction 方法来提交事务和终结事务，这两个操作都会发送一个 EndTxnRequest 给 Transaction Coordinator。</p>
<p><strong>流程 5.1</strong>：EndTxnRequest。Producer 发送一个 EndTxnRequest 给 Transaction Coordinator，然后执行如下操作：</p>
<ul>
<li>Transaction Coordinator 会把 PREPARE_COMMIT or PREPARE_ABORT 消息写入到 transaction log 中记录</li>
<li>执行流程 5.2</li>
<li>执行流程 5.3</li>
</ul>
<p><strong>流程 5.2</strong>：WriteTxnMarkerRequest</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">WriteTxnMarkersRequest =&gt; [CoorinadorEpoch PID Epoch Marker [Topic [Partition]]]</span><br><span class="line"> CoordinatorEpoch =&gt; int32</span><br><span class="line"> PID =&gt; int64</span><br><span class="line"> Epoch =&gt; int16</span><br><span class="line"> Marker =&gt; boolean (false(0) means ABORT, true(1) means COMMIT)</span><br><span class="line"> Topic =&gt; string</span><br><span class="line"> Partition =&gt; int32</span><br></pre></td></tr></table></figure>
<ul>
<li>对于 Producer 生产的消息。Tranaction Coordinator 会发送 WriteTxnMarkerRequest 给当前事务涉及到每个&lt;topic,partion&gt;的 leader，leader 收到请求后，会写入一个 COMMIT(PID) 或者 ABORT(PID)的控制信息到 data log 中</li>
<li>对于消费者偏移量信息，如果在这个事务里面包含_consumer-offsets 主题。Tranaction Coordinator 会发送 WriteTxnMarkerRequest 给 Transaction Coordinartor，Transaction Coordinartor 收到请求后，会写入一个 COMMIT(PID) 或者 ABORT(PID)的控制信息到 data log 中。</li>
</ul>
<p><strong>流程 5.3：</strong>Transaction Coordinator 会将最终的 COMPLETE_COMMIT 或 COMPLETE_ABORT 消息写入 Transaction Log 中以标明该事务结束。</p>
<ul>
<li>只会保留这个事务对应的 PID 和 timstamp。然后把当前事务其他相关消息删除掉，包括 PID 和 tranactionId 的映射关系。</li>
</ul>
<h5 id="文件类型和查看命令"><a href="#文件类型和查看命令" class="headerlink" title="文件类型和查看命令"></a>文件类型和查看命令</h5><p>kafka 文件主要包括 broker 的 data（主题：test）、事务协调器对应的 transaction_log（主题：__tranaction_state）、偏移量信息（主题:_consumer_offsets）三种类型。如下图</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/1-2-207x300.png"></div><br></p>
<p>这三种文件类型其实都是 topic 的分区，所以对于每一个目录都包含<em>.log、</em>.index、<em>.timeindex、</em>.txnindex 文件（仅这个文件是为了实现事务属性引入的）。segment 和 segmengt 对应 index、timeindex、txnindex 文件命名中序号表示的是第几个消息。如下图中，00000000000000368769.index 和 00000000000000568769.log 中“368969”就是表示文件中存储的第一个消息是 468969 个消息。</p>
<p>对于索引文案包含两部分：</p>
<ul>
<li>baseOffset：索引对应 segment 文件中的第几条 message。</li>
<li>position：在 segment 中的绝对位置。</li>
</ul>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/67930538-300x179.png"></div><br></p>
<p>查看文件内容：</p>
<p>bin/kafka-run-class.sh kafka.tools.DumpLogSegments –files /Users/wuzhonghu/data/kafka-logs/firtstopic-0/00000000000000000002.log –print-data-log</p>
<h5 id="ControlMessage-和-Transaction-markers"><a href="#ControlMessage-和-Transaction-markers" class="headerlink" title="ControlMessage 和 Transaction markers"></a>ControlMessage 和 Transaction markers</h5><p>Trasaction markers 就是 kafka 为了实现事务定义的 Controll Message。这个消息和数据消息都存放在 log 中，在 Consumer 读取事务消息时有用，可以参考下面章节-4.5.1 老版本-读取事务消息顺序。</p>
<h5 id="Transaction-Coordinator-和-Transaction-Log"><a href="#Transaction-Coordinator-和-Transaction-Log" class="headerlink" title="Transaction Coordinator 和 Transaction Log"></a>Transaction Coordinator 和 Transaction Log</h5><p>Transaction Log 如下放置在“_tranaction_state”主题下面，默认是 50 个分区，每一个分区中文件格式和 broker 存储消息是一样的,都有 log/index/timeindex 文件，如下：</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/57646045.png"></div><br></p>
<h4 id="8-5-5-消费读取事务消息-READ-COMMITED"><a href="#8-5-5-消费读取事务消息-READ-COMMITED" class="headerlink" title="8.5.5. 消费读取事务消息(READ_COMMITED)"></a>8.5.5. 消费读取事务消息(READ_COMMITED)</h4><p>Consumer 为了实现事务，新增了一个 isolation.level 配置，有两个值如下，</p>
<ul>
<li>READ_UNCOMMITTED，类似于没有事务属性的消费者。</li>
<li>READ_COMMITED，只获取执行了事务提交的消息。</li>
</ul>
<p>在本小节中我们主要讲 READ_COMMITED 模式下读取消息的流程的两种版本的演化</p>
<h5 id="老版本-读取事务消息顺序"><a href="#老版本-读取事务消息顺序" class="headerlink" title="老版本-读取事务消息顺序"></a>老版本-读取事务消息顺序</h5><p>如下图中，按顺序保存到 broker 中消息有：事务 1 消息 T1-M1、对于事务 2 的消息有 T2-M1、事务 1 消息 T1-M2、非事务消息 M1，最终到达 client 端的循序是 M1-&gt; T2-M1 -&gt; T1-M1 -&gt; T1-M2。</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/84999567.png"></div><br></p>
<p>具体步骤如下：</p>
<ul>
<li><strong>step1</strong> Consumer 接受到事务消息 T1-M1、T2-M2、T1-M2 和非事务消息 M1，因为没有收到事务 T1 和 T2 的控制消息，所以此时把事务相关消息 T1-M1、T2-M2、T1-M2 保存到内存，然后只把非事务消息 M1 返回给 client。</li>
<li><strong>step2</strong> Consumer 接受到事务 2 的控制消息 T2-C，此时就把事务消息 T2-M1 发送给 Clinet。</li>
<li><strong>step3</strong> C onsumer 接受到事务 1 的控制消息 T1-C,此时就把事务消息 T1-M1 和 T1-M2 发送给 Client</li>
</ul>
<h5 id="新版本-读取事务消息顺序"><a href="#新版本-读取事务消息顺序" class="headerlink" title="新版本-读取事务消息顺序"></a>新版本-读取事务消息顺序</h5><p>第一种方式，需要在 consumer 客户端缓存消息，当存在耗时比较长的事务时，占用客户端大量的内存资源。为了解决这个问题，通过 LSO 和 Abort Index 文件来解决这个问题，参考：</p>
<p><a href="https://docs.google.com/document/d/1Rlqizmk7QCDe8qAnVW5e5X8rGvn6m2DCR3JR2yqwVjc/edit" target="_blank" rel="noopener">https://docs.google.com/document/d/1Rlqizmk7QCDe8qAnVW5e5X8rGvn6m2DCR3JR2yqwVjc/edit</a></p>
<p>（1） LSO，Last stable offset。Broker 在缓存中维护了所有处于运行状态的事务对应的 initial offsets,LSO 的值就是这些 offsets 中最小值-1。这样在 LSO 之前数据都是已经 commit 或者 abort 的数据，只有这些数据才对 Consumer 可见，即 consumer 读取数据只能读取到 LSO 的位置。</p>
<ul>
<li>LSO 并没有持久化某一个位置，而是实时计算出来的，并保存在缓存中。</li>
</ul>
<p>（2）Absort Index 文件</p>
<p>Conusmer 发送 FetchRequest 中，新增了 Isolation 字段，表示是那种模式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ReplicaId MaxWaitTime MinBytes [TopicName [Partition FetchOffset MaxBytes]]</span><br><span class="line"></span><br><span class="line">  ReplicaId =&gt; int32</span><br><span class="line">  MaxWaitTime =&gt; int32</span><br><span class="line">  MinBytes =&gt; int32</span><br><span class="line">  TopicName =&gt; string</span><br><span class="line">  Partition =&gt; int32</span><br><span class="line">  FetchOffset =&gt; int64</span><br><span class="line">  MaxBytes =&gt; int32</span><br><span class="line">  Isolation =&gt; READ_COMMITTED | READ_UNCOMMITTED</span><br></pre></td></tr></table></figure>
<p>返回数据类型为 FetchResponse 的格式为：</p>
<p>ThrottleTime [TopicName [Partition ErrorCode HighwaterMarkOffset AbortedTransactions MessageSetSize MessageSet]]</p>
<p>对应各个给字段类型为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ThrottleTime =&gt; int32</span><br><span class="line"> TopicName =&gt; string</span><br><span class="line"> Partition =&gt; int32</span><br><span class="line"> ErrorCode =&gt; int16</span><br><span class="line"> HighwaterMarkOffset =&gt; int64</span><br><span class="line"> AbortedTransactions =&gt; [PID FirstOffset]</span><br><span class="line">   PID =&gt; int64</span><br><span class="line">   FirstOffset =&gt; int64</span><br><span class="line"> MessageSetSize =&gt; int32</span><br></pre></td></tr></table></figure>
<ul>
<li>设置成 READ_UNCOMMITTED 模式时, the AbortedTransactions array is null.</li>
<li>设置为 READ_COMMITTED 时，the Last Stable Offset(LSO)，当事务提交之后，LSO 向前移动 offset</li>
</ul>
<p>数据如下：</p>
<ul>
<li>存放数据的 log</li>
</ul>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/1-3.png"></div><br></p>
<ul>
<li>存放 Absort Index 的内容如下：</li>
</ul>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/3-2.png"></div><br></p>
<p>执行读取数据流程如下：</p>
<p><strong>step1:</strong> 假设 consumer 读取数据的 fetched offsets 的区间是 0 到 4。</p>
<ul>
<li>首先，broker 读取 data log 中数据</li>
</ul>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/11-1.png"></div><br></p>
<ul>
<li>然后，broker 依次读取 abort index 的内容，发现 LSO 大于等于 4 就停止。如上可以获取到 P2 对应的 offset 从 2 到 5 的消息都是被丢弃的：</li>
</ul>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/12-1.png"></div><br></p>
<ul>
<li>最后，broker 将上面 data log 和 abort index 中满足条件的数据返回给 consumer。</li>
</ul>
<p><strong>step2 ：</strong>在 consumer 端根据 absrot index 中返回的内容，过滤丢弃的消息，最终给用户消息为</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/13-300x103.png"></div><br></p>
<h5 id="Absorted-Transaction-Index"><a href="#Absorted-Transaction-Index" class="headerlink" title="Absorted Transaction Index"></a>Absorted Transaction Index</h5><p>在 broker 中数据中新增一个索引文件，保存 aborted tranasation 对应的 offsets，只有事务执行 abort 时，才会往这个文件新增一个记录，初始这个文件是不存在的，只有第一条 abort 时，才会创建这个文件。</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/2-1-300x149.png"></div><br></p>
<p>这个索引文件结构的每一行结构是 TransactionEntry：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Version =&gt; int16</span><br><span class="line"> PID =&gt; int64</span><br><span class="line"> FirstOffset =&gt; int64</span><br><span class="line"> LastOffset =&gt; int64</span><br><span class="line"> LastStableOffset =&gt; int64</span><br></pre></td></tr></table></figure>
<p>当 broker 接受到控制消息（producer 执行 commitTransaction()或者 abortTransaction()）时, 执行如下操作:</p>
<p>(1)计算 LSO。</p>
<p>Broker 在缓存中维护了所有处于运行状态的事务对应的 initial offsets,LSO 的值就是这些 offsets 中最小值-1。</p>
<p>举例说明下 LSO 的计算，对于一个 data log 中内如如下</p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/31.png"></div><br></p>
<p>对应的 abort index 文件中内如如下：<strong>LSO 是递增的</strong></p>
<p><br><div align="center"><img src="http://www.heartthinkdo.com/wp-content/uploads/2018/05/32.png"></div><br></p>
<p>(2)第二步 如果事务是提交状态，则在索引文件中新增 TransactionEntry。</p>
<p>(3)第三步 从 active 的 tranaction set 中移除这个 transaton，然后更新 LSO。</p>
<h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><p>1、问题 1：producer 通过事务提交消息时抛异常了， 对于使用非事务的消费者，是否可以获取此消息？</p>
<p>对于事务消息，必须是执行 commit 或者 abstort 之后，消息才对消费者可见，即使是非事务的消费者。只是非事务消费者相比事务消费者区别，在于可以读取执行了 absort 的消息。</p>
<h3 id="8-6-其他思考"><a href="#8-6-其他思考" class="headerlink" title="8.6. 其他思考"></a>8.6. 其他思考</h3><p>1、如何保证消息不丢。</p>
<p>（1）在消费端可以建立一个日志表，和业务处理在一个事务</p>
<p>定时扫描没有表发送没有被处理的消息</p>
<p>（2）消费端，消费消息之后，修改消息表的中消息状态为已处理成功。</p>
<p>2、如何保证消息提交和业务处理在同一个事务内完成</p>
<p>在消费端可以建立一个日志表，和业务处理在一个事务</p>
<p>3、消费者角度，如何保证消息不被重复消费。</p>
<p>（1）通过 seek 操作</p>
<p>（2）通过 kafka 事务操作。</p>
<p>4、生产者角度，如何保证消息不重复生产</p>
<p>（1）kakfka 幂等性</p>
<h2 id="9-资料"><a href="#9-资料" class="headerlink" title="9. 资料"></a>9. 资料</h2><h3 id="9-1-官方资料"><a href="#9-1-官方资料" class="headerlink" title="9.1. 官方资料"></a>9.1. 官方资料</h3><p><a href="https://github.com/apache/kafka" target="_blank" rel="noopener">Github</a> | <a href="https://kafka.apache.org/documentation/" target="_blank" rel="noopener">官方文档</a></p>
<h3 id="9-2-第三方资料"><a href="#9-2-第三方资料" class="headerlink" title="9.2. 第三方资料"></a>9.2. 第三方资料</h3><ul>
<li><a href="https://github.com/yahoo/kafka-manager" target="_blank" rel="noopener">Kafka Manager</a> - Kafka 管理工具</li>
<li><a href="http://www.infoq.com/cn/articles/kafka-analysis-part-1" target="_blank" rel="noopener">Kafka 剖析（一）：Kafka 背景及架构介绍</a></li>
<li><a href="https://hackernoon.com/thorough-introduction-to-apache-kafka-6fbf2989bbc1" target="_blank" rel="noopener">Thorough Introduction to Apache Kafka</a></li>
<li><a href="http://www.heartthinkdo.com/?p=2040#43" target="_blank" rel="noopener">Kafak(04) Kafka 生产者事务和幂等</a></li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/blog/tags/java/" rel="tag"># java</a>
          
            <a href="/blog/tags/分布式/" rel="tag"># 分布式</a>
          
            <a href="/blog/tags/javaweb/" rel="tag"># javaweb</a>
          
            <a href="/blog/tags/mq/" rel="tag"># mq</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2018/06/12/programming/java/javaweb/architecture/分布式架构/" rel="next" title="分布式架构">
                <i class="fa fa-chevron-left"></i> 分布式架构
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2018/06/13/programming/java/javaweb/standalone/security/shiro/" rel="prev" title="Shiro">
                Shiro <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/blog/images/avatar.gif" alt="Zhang Peng">
            
              <p class="site-author-name" itemprop="name">Zhang Peng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/blog/archives/">
              
                  <span class="site-state-item-count">381</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/blog/categories/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/blog/tags/index.html">
                  <span class="site-state-item-count">76</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/blog/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/dunwu" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:forbreak@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Kafka"><span class="nav-number">1.</span> <span class="nav-text">Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-概述"><span class="nav-number">1.1.</span> <span class="nav-text">1. 概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-分布式"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1. 分布式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-容错"><span class="nav-number">1.1.2.</span> <span class="nav-text">1.2. 容错</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-提交日志"><span class="nav-number">1.1.3.</span> <span class="nav-text">1.3. 提交日志</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-消息队列"><span class="nav-number">1.1.4.</span> <span class="nav-text">1.4. 消息队列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-5-为什么要使用消息系统"><span class="nav-number">1.1.5.</span> <span class="nav-text">1.5. 为什么要使用消息系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-6-Kafka-的关键功能"><span class="nav-number">1.1.6.</span> <span class="nav-text">1.6. Kafka 的关键功能</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-7-Kafka-基本概念"><span class="nav-number">1.1.7.</span> <span class="nav-text">1.7. Kafka 基本概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-8-Kafka-核心-API"><span class="nav-number">1.1.8.</span> <span class="nav-text">1.8. Kafka 核心 API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-9-Topic-和日志"><span class="nav-number">1.1.9.</span> <span class="nav-text">1.9. Topic 和日志</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Kafka-工作原理"><span class="nav-number">1.2.</span> <span class="nav-text">2. Kafka 工作原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-持久化"><span class="nav-number">1.3.</span> <span class="nav-text">3. 持久化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-复制"><span class="nav-number">1.4.</span> <span class="nav-text">4. 复制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-流处理"><span class="nav-number">1.5.</span> <span class="nav-text">5. 流处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-无状态处理"><span class="nav-number">1.5.1.</span> <span class="nav-text">5.1. 无状态处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-有状态处理"><span class="nav-number">1.5.2.</span> <span class="nav-text">5.2. 有状态处理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-Kafka-应用场景"><span class="nav-number">1.6.</span> <span class="nav-text">6. Kafka 应用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-幂等性"><span class="nav-number">1.7.</span> <span class="nav-text">7. 幂等性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-幂等性实现"><span class="nav-number">1.7.1.</span> <span class="nav-text">7.1. 幂等性实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-1-PID-和-Sequence-Number"><span class="nav-number">1.7.1.1.</span> <span class="nav-text">7.1.1. PID 和 Sequence Number</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-2-生成-PID-的流程"><span class="nav-number">1.7.1.2.</span> <span class="nav-text">7.1.2. 生成 PID 的流程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-幂等性的应用实例"><span class="nav-number">1.7.2.</span> <span class="nav-text">7.2. 幂等性的应用实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-事务"><span class="nav-number">1.8.</span> <span class="nav-text">8. 事务</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-事务属性理解"><span class="nav-number">1.8.1.</span> <span class="nav-text">8.1. 事务属性理解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-引入事务目的"><span class="nav-number">1.8.2.</span> <span class="nav-text">8.2. 引入事务目的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-事务操作的-API"><span class="nav-number">1.8.3.</span> <span class="nav-text">8.3. 事务操作的 API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-4-事务属性的应用实例"><span class="nav-number">1.8.4.</span> <span class="nav-text">8.4. 事务属性的应用实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-1-相关属性配置"><span class="nav-number">1.8.4.1.</span> <span class="nav-text">8.4.1. 相关属性配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-2-只有写"><span class="nav-number">1.8.4.2.</span> <span class="nav-text">8.4.2. 只有写</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-3-消费-生产并存（consume-transform-produce）"><span class="nav-number">1.8.4.3.</span> <span class="nav-text">8.4.3. 消费-生产并存（consume-transform-produce）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-4-4-只有读"><span class="nav-number">1.8.4.4.</span> <span class="nav-text">8.4.4. 只有读</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-5-生产者事务的实现"><span class="nav-number">1.8.5.</span> <span class="nav-text">8.5. 生产者事务的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-1-相关配置"><span class="nav-number">1.8.5.1.</span> <span class="nav-text">8.5.1. 相关配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-2-幂等性和事务性的关系"><span class="nav-number">1.8.5.2.</span> <span class="nav-text">8.5.2. 幂等性和事务性的关系</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#两者关系"><span class="nav-number">1.8.5.2.1.</span> <span class="nav-text">两者关系</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#tranaction-id-、productid-和-epoch"><span class="nav-number">1.8.5.2.2.</span> <span class="nav-text">tranaction id 、productid 和 epoch</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-3-事务最佳实践-单实例的事务性"><span class="nav-number">1.8.5.3.</span> <span class="nav-text">8.5.3. 事务最佳实践-单实例的事务性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-4-Consume-transform-Produce-的流程"><span class="nav-number">1.8.5.4.</span> <span class="nav-text">8.5.4. Consume-transform-Produce 的流程</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#文件类型和查看命令"><span class="nav-number">1.8.5.4.1.</span> <span class="nav-text">文件类型和查看命令</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ControlMessage-和-Transaction-markers"><span class="nav-number">1.8.5.4.2.</span> <span class="nav-text">ControlMessage 和 Transaction markers</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Transaction-Coordinator-和-Transaction-Log"><span class="nav-number">1.8.5.4.3.</span> <span class="nav-text">Transaction Coordinator 和 Transaction Log</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-5-5-消费读取事务消息-READ-COMMITED"><span class="nav-number">1.8.5.5.</span> <span class="nav-text">8.5.5. 消费读取事务消息(READ_COMMITED)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#老版本-读取事务消息顺序"><span class="nav-number">1.8.5.5.1.</span> <span class="nav-text">老版本-读取事务消息顺序</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#新版本-读取事务消息顺序"><span class="nav-number">1.8.5.5.2.</span> <span class="nav-text">新版本-读取事务消息顺序</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Absorted-Transaction-Index"><span class="nav-number">1.8.5.5.3.</span> <span class="nav-text">Absorted Transaction Index</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#问题"><span class="nav-number">1.8.5.5.4.</span> <span class="nav-text">问题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-6-其他思考"><span class="nav-number">1.8.6.</span> <span class="nav-text">8.6. 其他思考</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-资料"><span class="nav-number">1.9.</span> <span class="nav-text">9. 资料</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#9-1-官方资料"><span class="nav-number">1.9.1.</span> <span class="nav-text">9.1. 官方资料</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-2-第三方资料"><span class="nav-number">1.9.2.</span> <span class="nav-text">9.2. 第三方资料</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2015 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-paper-plane"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhang Peng</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/blog/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/blog/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/blog/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/blog/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/blog/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/blog/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/blog/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === '') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
